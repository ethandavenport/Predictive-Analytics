{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0dd3776",
   "metadata": {},
   "source": [
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc51ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # dataframe/data cleaning/manipulation\n",
    "import numpy as np # array computations\n",
    "from matplotlib import pyplot as plt # plotting/graphing\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.tree import plot_tree, export_text, DecisionTreeClassifier # Decision tree algorithm and plotting functions for the Decision tree\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier # Bagging, Random Forest, and Boosting algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier # K-Nearest Neighbor Algorithm\n",
    "from sklearn.linear_model import LogisticRegression # Logistic Regression Algorithm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict # train test split and cross validation accuracy/prediction functions\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, roc_auc_score # Various model evaluation metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffcfc34",
   "metadata": {},
   "source": [
    "Note: If you are using Google Colab, you must upload the `hr.csv` file from Canvas by doing the following:\n",
    "\n",
    "* On the left-side bar, click the folder icon.\n",
    "* Click the 'Upload to session storage' button.\n",
    "* Upload the CSV file; it will appear below the 'sample_data' folder.\n",
    "\n",
    "**Unfortunately, this process must be done every time the runtime is disconnected - just a quirk with Google Colab.**\n",
    "\n",
    "If you are using Jupyter notebook, just make sure the CSV file is in the same folder location as this .ipynb file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfae5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df = pd.read_csv('hr.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d28076",
   "metadata": {},
   "source": [
    "# Binarize categorial variables and set X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16607b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_df_binarized = pd.get_dummies(hr_df)\n",
    "X = hr_df_binarized.drop(columns=['Attrition'])\n",
    "y = hr_df_binarized.Attrition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716acf3",
   "metadata": {},
   "source": [
    "# Create Function - Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e44e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_score(mymodel, X, y, mycv):\n",
    "# To use this function, all we need to do is feed it our model of interest, X, y, and the number of folds for cross-validation.\n",
    "\n",
    "    # Calculate and print the cross-validation accuracy\n",
    "    cross_val_accuracy = round(cross_val_score(mymodel, X, y, cv = mycv).mean()*100,2)\n",
    "    print(f\"{mycv}-Fold Cross-Validation Classification Accuracy: {cross_val_accuracy:.2f} %\")\n",
    "\n",
    "    # Calculate and print the cross-validation ROC AUC\n",
    "    cross_val_accuracy_roc_auc = round(cross_val_score(mymodel, X, y, cv =  mycv, scoring = 'roc_auc').mean()*100,2)\n",
    "    print(f\"\\n{mycv}-Fold Cross-Validation ROC AUC: {cross_val_accuracy_roc_auc:.2f} %\")\n",
    "\n",
    "    # Calculate the confusion matrix and print the true positives/negatives and false positives/negatives\n",
    "    predictions = cross_val_predict(mymodel, X, y, cv = mycv)\n",
    "    confusion = confusion_matrix(y, predictions)\n",
    "    tn, fp, fn, tp = confusion.ravel()\n",
    "    print(f\"\\nTrue Negatives: {tn}, False Positives: {fp}, False Negatives: {fn}, True Positives: {tp}\")\n",
    "\n",
    "    # Calculate and print precision and recall:\n",
    "    print(\"\\nPrecision:\", round(precision_score(y, predictions)*100,2))\n",
    "    print(\"\\nRecall:\", round(recall_score(y, predictions)*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccda461",
   "metadata": {},
   "source": [
    "# Instructions and Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a69e9",
   "metadata": {},
   "source": [
    "**For this Instapoll assignment, your task is to take the code snippets used in Ensemble_Models_Final relating to bagging, random forest, and/or boosting, and play with the base model or hyper-parameter settings to try and maximize your 10-Fold Cross Validation ROC AUC.**\n",
    "\n",
    "- **For a bagging model, try to exceed a 10-Fold Cross-Validation ROC AUC of 78.72%.**\n",
    "\n",
    "- **For a random forest model, try to exceed a 10-Fold Cross-Validation ROC AUC of 79.78%.**\n",
    "\n",
    "- **For a boosting model, try to exceed a 10-Fold Cross-Validation ROC AUC of 81.04%.**\n",
    "\n",
    "The report_score function has been provided for you.\n",
    "\n",
    "Please try your best and if you have any questions, please reach out to the Professor or TA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3d68ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validation Classification Accuracy: 85.92 %\n",
      "\n",
      "10-Fold Cross-Validation ROC AUC: 79.21 %\n",
      "\n",
      "True Negatives: 1212, False Positives: 21, False Negatives: 186, True Positives: 51\n",
      "\n",
      "Precision: 70.83\n",
      "\n",
      "Recall: 21.52\n"
     ]
    }
   ],
   "source": [
    "base_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 6, random_state = 3)\n",
    "bagging_model = BaggingClassifier(estimator = base_model, n_estimators = 50, random_state = 3).fit(X, y)\n",
    "report_score(bagging_model, X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c30d33f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validation Classification Accuracy: 85.85 %\n",
      "\n",
      "10-Fold Cross-Validation ROC AUC: 80.92 %\n",
      "\n",
      "True Negatives: 1225, False Positives: 8, False Negatives: 200, True Positives: 37\n",
      "\n",
      "Precision: 82.22\n",
      "\n",
      "Recall: 15.61\n"
     ]
    }
   ],
   "source": [
    "random_forest_model = RandomForestClassifier(criterion = 'entropy', n_estimators = 100, max_features = 6).fit(X,y)\n",
    "report_score(random_forest_model, X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f04967c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-Fold Cross-Validation Classification Accuracy: 87.21 %\n",
      "\n",
      "10-Fold Cross-Validation ROC AUC: 82.26 %\n",
      "\n",
      "True Negatives: 1224, False Positives: 9, False Negatives: 179, True Positives: 58\n",
      "\n",
      "Precision: 86.57\n",
      "\n",
      "Recall: 24.47\n"
     ]
    }
   ],
   "source": [
    "adaboost_model = AdaBoostClassifier(algorithm=\"SAMME.R\", n_estimators=20, random_state = 3)\n",
    "bagging_model_nested = BaggingClassifier(estimator = adaboost_model, n_estimators=20, random_state = 3)\n",
    "report_score(bagging_model_nested, X, y, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
